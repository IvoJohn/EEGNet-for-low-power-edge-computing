{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original implementation: https://github.com/MHersche/eegnet-based-embedded-bci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "current_directory = Path().cwd()\n",
    "parent_directory = current_directory.parent\n",
    "sys.path.insert(0, str(parent_directory))\n",
    "\n",
    "from modules.dataloader import CreateIDs, DataSet\n",
    "from modules.architecture import EEGNet_lowpower\n",
    "from training_loop import TrainingLoop\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLING_FACTOR = 2\n",
    "NUMBER_OF_CHANNELS = 64\n",
    "N_SAMPLES_PER_RECORDING = 5\n",
    "TASK_MODE = 'all_tasks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ns - number of input samples in time domain\n",
    "* Nch - number of EEG channels\n",
    "* Ncl - number of classes\n",
    "* Nf - filter size of first temporal filter\n",
    "* Np - pooling length\n",
    "</br></br>\n",
    "* n - number of filters\n",
    "* p - padding strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model to cpu\n",
      "EEGNet_lowpower(\n",
      "  (temp_conv): TemporalConvolution(\n",
      "    (conv1): Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1), padding=same)\n",
      "    (conv2): Conv2d(8, 8, kernel_size=(64, 1), stride=(1, 1), padding=same)\n",
      "  )\n",
      "  (batch_norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (depthwise_conv): DepthWiseConvolution(\n",
      "    (conv1): Conv2d(8, 8, kernel_size=(64, 1), stride=(1, 1), padding=valid, groups=8)\n",
      "    (conv2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "  )\n",
      "  (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (elu_1): ELU(alpha=1.0)\n",
      "  (avg_pool_1): AvgPool2d(kernel_size=(1, 8), stride=8, padding=0)\n",
      "  (separable_conv): Conv2d(16, 16, kernel_size=(16, 1), stride=(1, 1), padding=same)\n",
      "  (batch_norm_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (elu_2): ELU(alpha=1.0)\n",
      "  (avg_pool_2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Linear(in_features=112, out_features=5, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "EEGNet = EEGNet_lowpower(task_mode=TASK_MODE)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('Using {} GPUs'.format(torch.cuda.device_count()))\n",
    "    EEGNet = nn.DataParallel(EEGNet)\n",
    "else:\n",
    "    print(f'Loading the model to {device}')\n",
    "print(EEGNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1414, 0.1920, 0.1864, 0.3120, 0.1682]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(1,1,64,480, device=device)\n",
    "output = EEGNet(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 109 patient's folders\n",
      "Data will be split with ratio 70.0% train, 20.0% val, 10.0% test\n",
      "Splitting data into train, val and test set according to recordings, val and test will use ceil int\n",
      "Checking train IDs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da2e1a758ad44428007d86df075fa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4895 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking validation IDs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde4417852f24b9d91de5f6a47a621a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking test IDs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a89b51685c4345b5a5390742214f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4245 train, 1350 validation, and 945 test IDs\n"
     ]
    }
   ],
   "source": [
    "dataset_path = ''\n",
    "\n",
    "train_ids, val_ids, test_ids = CreateIDs(dataset_path=dataset_path,\n",
    "n_samples_per_recording=N_SAMPLES_PER_RECORDING, task_mode=TASK_MODE, split_ratio=(0.7,0.2,0.1)).create()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset modes:\n",
    "1. rest_unrest - predicts T0 vs rest (2 classes), uses all runs\n",
    "2. left_right - predicts T0-T1-T2 (3 classes), uses runs 3,4,7,8,11,12, predicts left (T1) first or right first(T2)\n",
    "3. upper_lower - predicts T0-T1-T2 (3 classes), uses runs 5,6,9,10,13,14\n",
    "4. all tasks - predicts 5 classes (rest, left, right, both, feet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = DataSet(list_IDs=train_ids, dataset_path=dataset_path, sample_length=480, task_mode=TASK_MODE)\n",
    "validation_dataset = DataSet(list_IDs=val_ids, dataset_path=dataset_path, sample_length=480, task_mode=TASK_MODE)\n",
    "test_dataset = DataSet(list_IDs=test_ids, dataset_path=dataset_path, sample_length=480, task_mode=TASK_MODE)\n",
    "\n",
    "training_data_loader = DataLoader(training_dataset, batch_size=10,shuffle=True)\n",
    "validation_data_loader = DataLoader(training_dataset, batch_size=10,shuffle=True)\n",
    "test_data_loader = DataLoader(training_dataset, batch_size=10,shuffle=True)\n",
    "\n",
    "for x_train,y in training_data_loader:\n",
    "    break\n",
    "\n",
    "for x_test,y in test_data_loader:\n",
    "    break\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 minutes per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f605a332c94de5b23ed5b5747b2581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = ''\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "EEGNet = EEGNet_lowpower(task_mode=TASK_MODE).to(device)\n",
    "\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(EEGNet.parameters(), lr=0.001)\n",
    "\n",
    "training_loop = TrainingLoop(\n",
    "    model=EEGNet,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    training_DataLoader=training_data_loader,\n",
    "    epochs=2,\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "training_losses, validation_losses, lr_rates = training_loop.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training data:\n",
      "\n",
      "[[9.99433100e-01 1.80345756e-04 1.78987699e-04 1.00801830e-04\n",
      "  1.06763015e-04]\n",
      " [9.96871293e-01 7.78718037e-04 6.93718670e-04 9.11938667e-04\n",
      "  7.44326739e-04]\n",
      " [9.98851299e-01 3.54945456e-04 2.94102152e-04 2.17172113e-04\n",
      "  2.82415102e-04]\n",
      " [9.98517573e-01 4.17233416e-04 4.20516648e-04 2.30175050e-04\n",
      "  4.14459530e-04]\n",
      " [9.94980395e-01 1.41474023e-03 1.21363089e-03 1.11888011e-03\n",
      "  1.27233227e-03]\n",
      " [9.97337639e-01 8.59745138e-04 6.36652694e-04 5.84352703e-04\n",
      "  5.81616419e-04]\n",
      " [9.96548831e-01 1.00441801e-03 5.84950321e-04 7.08344625e-04\n",
      "  1.15337432e-03]\n",
      " [9.97514248e-01 7.70908839e-04 6.12541335e-04 3.54911404e-04\n",
      "  7.47310580e-04]\n",
      " [9.98891532e-01 3.60714621e-04 2.20241083e-04 2.50124111e-04\n",
      "  2.77285988e-04]\n",
      " [9.98627186e-01 4.28594387e-04 3.28698690e-04 2.74863385e-04\n",
      "  3.40755156e-04]]\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.]])\n",
      "\n",
      "\n",
      "\n",
      "Test data:\n",
      "\n",
      "[[9.9815863e-01 5.3797901e-04 3.4520397e-04 3.5136586e-04 6.0680101e-04]\n",
      " [9.9844992e-01 5.1367935e-04 3.0428835e-04 2.4002878e-04 4.9190765e-04]\n",
      " [9.9677223e-01 9.3338825e-04 7.1714976e-04 7.0673745e-04 8.7046076e-04]\n",
      " [9.9760997e-01 6.8992551e-04 5.2542856e-04 4.4515889e-04 7.2955625e-04]\n",
      " [9.9842501e-01 4.8129910e-04 3.0209022e-04 3.6395818e-04 4.2766047e-04]\n",
      " [9.9810886e-01 6.5541337e-04 4.9784227e-04 3.4569870e-04 3.9232991e-04]\n",
      " [9.9968839e-01 1.0240991e-04 7.1644412e-05 6.0102542e-05 7.7587334e-05]\n",
      " [9.9883133e-01 4.2423879e-04 2.3859176e-04 2.0950432e-04 2.9622429e-04]\n",
      " [9.9702990e-01 1.0666889e-03 7.9588569e-04 4.8310187e-04 6.2438095e-04]\n",
      " [9.9725831e-01 7.8234350e-04 9.5603254e-04 4.6459594e-04 5.3862500e-04]]\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "out = EEGNet(x_train)\n",
    "print('Checking training data:\\n')\n",
    "print(out.detach().cpu().numpy())\n",
    "print(y)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('Test data:\\n')\n",
    "out = EEGNet(x_test)\n",
    "print(out.detach().cpu().numpy())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_test,y_test in test_data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_class_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# For test data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m EEGNet(x_test)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 6\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mto_class_indices\u001b[49m(test_predictions)  \u001b[38;5;66;03m# Convert predictions to class indices\u001b[39;00m\n\u001b[1;32m      7\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m to_class_indices(y_test\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# Convert labels to class indices\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate metrics for test data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_class_indices' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# For test data\n",
    "test_predictions = EEGNet(x_test).detach().cpu().numpy()\n",
    "test_predictions = to_class_indices(test_predictions)  # Convert predictions to class indices\n",
    "test_labels = to_class_indices(y_test.numpy())  # Convert labels to class indices\n",
    "\n",
    "# Calculate metrics for test data\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_precision = precision_score(test_labels, test_predictions, average='macro')  # Use 'macro' or 'weighted' for multi-class\n",
    "test_recall = recall_score(test_labels, test_predictions, average='macro')  # Use 'macro' or 'weighted' for multi-class\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='macro')  # Use 'macro' or 'weighted' for multi-class\n",
    "\n",
    "print('Test Data Metrics:')\n",
    "print(f'Accuracy: {test_accuracy}')\n",
    "print(f'Precision: {test_precision}')\n",
    "print(f'Recall: {test_recall}')\n",
    "print(f'F1 Score: {test_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9816e-01, 5.3798e-04, 3.4520e-04, 3.5137e-04, 6.0680e-04],\n",
      "        [9.9845e-01, 5.1368e-04, 3.0429e-04, 2.4003e-04, 4.9191e-04],\n",
      "        [9.9677e-01, 9.3339e-04, 7.1715e-04, 7.0674e-04, 8.7046e-04],\n",
      "        [9.9761e-01, 6.8993e-04, 5.2543e-04, 4.4516e-04, 7.2956e-04],\n",
      "        [9.9843e-01, 4.8130e-04, 3.0209e-04, 3.6396e-04, 4.2766e-04],\n",
      "        [9.9811e-01, 6.5541e-04, 4.9784e-04, 3.4570e-04, 3.9233e-04],\n",
      "        [9.9969e-01, 1.0241e-04, 7.1644e-05, 6.0103e-05, 7.7587e-05],\n",
      "        [9.9883e-01, 4.2424e-04, 2.3859e-04, 2.0950e-04, 2.9622e-04],\n",
      "        [9.9703e-01, 1.0667e-03, 7.9589e-04, 4.8310e-04, 6.2438e-04],\n",
      "        [9.9726e-01, 7.8234e-04, 9.5603e-04, 4.6460e-04, 5.3862e-04]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "out = EEGNet(x_test)\n",
    "print(out)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('bci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ff175f57731f1b78c220f55f60fad91a8c47bf080aca4d5e321830db8b00db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
