{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original implementation: https://github.com/MHersche/eegnet-based-embedded-bci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "current_directory = Path().cwd()\n",
    "parent_directory = current_directory.parent\n",
    "sys.path.insert(0, str(parent_directory))\n",
    "\n",
    "from modules.dataloader import CreateIDs, DataSet\n",
    "from modules.architecture import EEGNet_lowpower\n",
    "from training_loop import TrainingLoop\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSAMPLING_FACTOR = 2\n",
    "NUMBER_OF_CHANNELS = 64\n",
    "N_SAMPLES_PER_RECORDING = 5\n",
    "TASK_MODE = 'all_tasks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ns - number of input samples in time domain\n",
    "* Nch - number of EEG channels\n",
    "* Ncl - number of classes\n",
    "* Nf - filter size of first temporal filter\n",
    "* Np - pooling length\n",
    "</br></br>\n",
    "* n - number of filters\n",
    "* p - padding strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model to cpu\n",
      "EEGNet_lowpower(\n",
      "  (temp_conv): TemporalConvolution(\n",
      "    (conv1): Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1), padding=same)\n",
      "    (conv2): Conv2d(8, 8, kernel_size=(64, 1), stride=(1, 1), padding=same)\n",
      "  )\n",
      "  (batch_norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (depthwise_conv): DepthWiseConvolution(\n",
      "    (conv1): Conv2d(8, 8, kernel_size=(64, 1), stride=(1, 1), padding=valid, groups=8)\n",
      "    (conv2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), padding=valid)\n",
      "  )\n",
      "  (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (elu_1): ELU(alpha=1.0)\n",
      "  (avg_pool_1): AvgPool2d(kernel_size=(1, 8), stride=8, padding=0)\n",
      "  (separable_conv): Conv2d(16, 16, kernel_size=(16, 1), stride=(1, 1), padding=same)\n",
      "  (batch_norm_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (elu_2): ELU(alpha=1.0)\n",
      "  (avg_pool_2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Linear(in_features=112, out_features=5, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "EEGNet = EEGNet_lowpower(task_mode=TASK_MODE)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print('Using {} GPUs'.format(torch.cuda.device_count()))\n",
    "    EEGNet = nn.DataParallel(EEGNet)\n",
    "else:\n",
    "    print(f'Loading the model to {device}')\n",
    "print(EEGNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1414, 0.1920, 0.1864, 0.3120, 0.1682]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(1,1,64,480, device=device)\n",
    "output = EEGNet(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 109 patient's folders\n",
      "Data will be split with ratio 70.0% train, 20.0% val, 10.0% test\n",
      "Splitting data into train, val and test set according to recordings, val and test will use ceil int\n",
      "Checking train IDs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da2e1a758ad44428007d86df075fa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4895 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking validation IDs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde4417852f24b9d91de5f6a47a621a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking test IDs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a89b51685c4345b5a5390742214f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1090 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4245 train, 1350 validation, and 945 test IDs\n"
     ]
    }
   ],
   "source": [
    "dataset_path = ''\n",
    "\n",
    "train_ids, val_ids, test_ids = CreateIDs(dataset_path=dataset_path,\n",
    "n_samples_per_recording=N_SAMPLES_PER_RECORDING, task_mode=TASK_MODE, split_ratio=(0.7,0.2,0.1)).create()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset modes:\n",
    "1. rest_unrest - predicts T0 vs rest (2 classes), uses all runs\n",
    "2. left_right - predicts T0-T1-T2 (3 classes), uses runs 3,4,7,8,11,12, predicts left (T1) first or right first(T2)\n",
    "3. upper_lower - predicts T0-T1-T2 (3 classes), uses runs 5,6,9,10,13,14\n",
    "4. all tasks - predicts 5 classes (rest, left, right, both, feet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = DataSet(list_IDs=train_ids, dataset_path=dataset_path, sample_length=480, task_mode=TASK_MODE)\n",
    "validation_dataset = DataSet(list_IDs=val_ids, dataset_path=dataset_path, sample_length=480, task_mode=TASK_MODE)\n",
    "test_dataset = DataSet(list_IDs=test_ids, dataset_path=dataset_path, sample_length=480, task_mode=TASK_MODE)\n",
    "\n",
    "training_data_loader = DataLoader(training_dataset, batch_size=10,shuffle=True)\n",
    "validation_data_loader = DataLoader(training_dataset, batch_size=10,shuffle=True)\n",
    "test_data_loader = DataLoader(training_dataset, batch_size=10,shuffle=True)\n",
    "\n",
    "for x_train,y in training_data_loader:\n",
    "    break\n",
    "\n",
    "for x_test,y in test_data_loader:\n",
    "    break\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f605a332c94de5b23ed5b5747b2581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = ''\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "EEGNet = EEGNet_lowpower(task_mode=TASK_MODE).to(device)\n",
    "\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(EEGNet.parameters(), lr=0.001)\n",
    "\n",
    "training_loop = TrainingLoop(\n",
    "    model=EEGNet,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    training_DataLoader=training_data_loader,\n",
    "    epochs=2,\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "training_losses, validation_losses, lr_rates = training_loop.run_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('bci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79ff175f57731f1b78c220f55f60fad91a8c47bf080aca4d5e321830db8b00db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
